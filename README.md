
# Sistema de RecomendaÃ§Ã£o de NotÃ­cias do Portal G1

Sistema de recomendaÃ§Ã£o hÃ­brido que combina filtragem colaborativa, anÃ¡lise de conteÃºdo, fatores temporais e de popularidade para gerar recomendaÃ§Ãµes personalizadas de notÃ­cias.

## Sobre o Projeto

### Autoria
**Grupo 60 - PÃ³s Tech FIAP - Engenharia de Machine Learning**

### Contexto AcadÃªmico
Este projeto foi desenvolvido como parte do curso de PÃ³s-GraduaÃ§Ã£o em Engenharia de Machine Learning da FIAP (Faculdade de InformÃ¡tica e AdministraÃ§Ã£o Paulista), representando a aplicaÃ§Ã£o prÃ¡tica dos conhecimentos adquiridos na Fase 5 - MLOPS.


## ğŸš€ Funcionalidades

- RecomendaÃ§Ãµes personalizadas por usuÃ¡rio
- Tratamento de cold start para novos usuÃ¡rios 
- Interface web para visualizaÃ§Ã£o das recomendaÃ§Ãµes
- API REST para integraÃ§Ã£o
- DocumentaÃ§Ã£o Swagger
- Sistema de logs e monitoramento
- IntegraÃ§Ã£o com MLflow para tracking de experimentos
- Processamento distribuÃ­do com PySpark

## ğŸ› ï¸ Tecnologias

- Python 3.8+
- TensorFlow 2.5+
- PySpark 3.2+
- Flask / Flask-RESTX
- MLflow
- HTML/CSS/JavaScript
- Bootstrap

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8+
- Java 8+ 
- Pip
- Virtualenv (recomendado)
- Docker


## âš™ï¸ InstalaÃ§Ã£o Local

Estas instruÃ§Ãµes permitirÃ£o que vocÃª execute uma cÃ³pia do projeto em sua mÃ¡quina local para fins de desenvolvimento e teste.

### 1. Clone o repositÃ³rio:
```bash
git clone https://github.com/cleberdevs/sistema-recomendacao-noticias-g1.git
cd sistema-recomendacao-noticias-g1
```

### 2. Crie e ative um ambiente virtual:
```bash
python -m venv venv
source venv/bin/activate  
```

### 3. Torne os scripts executÃ¡veis (Linux/Mac):
```bash
chmod +x scripts/start_mlflow.sh
chmod +x scripts/start_api.sh
chmod +x scripts/healthcheck.sh
chmod +x scripts/setup_environment.sh
```

### 4. Configure o ambiente:
```bash
./scripts/setup_environment.sh
```
### 5.ğŸ“ LocalizaÃ§Ã£o dos Dados Brutos

Os dados brutos devem ser colocados nos seguintes diretÃ³rios:


```
dados/
â”œâ”€â”€ brutos/
â”‚   â”œâ”€â”€ treino_parte1.csv
â”‚   â”œâ”€â”€ treino_parte2.csv
â”‚   â””â”€â”€ itens/
â”‚       â”œâ”€â”€ itens-parte1.csv
â”‚       â””â”€â”€ itens-parte2.csv
```



## ğŸš€ ExecuÃ§Ã£o Local

### 1. Inicie o servidor MLflow:
```bash
./scripts/start_mlflow.sh  
```

### 2. Inicie o pipeline:
```bash
python pipeline.py
```

### 3. Inicie a API:
```bash 
./scripts/start_api.sh  
```

### 4. Acesse a interface web da API:
```
http://localhost:8000
```

A documentaÃ§Ã£o Swagger estarÃ¡ disponÃ­vel localmente em:
```
http://localhost:8000/docs
```

## âš™ï¸ InstalaÃ§Ã£o Docker

Estas instruÃ§Ãµes permitirÃ£o que vocÃª execute uma cÃ³pia do projeto em sua mÃ¡quina local ou na nuvem para produÃ§Ã£o.

### 1. Clone o repositÃ³rio:
```bash
git clone https://github.com/cleberdevs/sistema-recomendacao-noticias-g1.git
cd sistema-recomendacao-noticias-g1
```
### 2. Crie os diretÃ³rios necessÃ¡rios:
```bash
mkdir -p dados/brutos/itens logs modelos/modelos_salvos
```
### 3.ğŸ“ LocalizaÃ§Ã£o dos Dados Brutos

Os dados brutos devem ser colocados nos seguintes diretÃ³rios:

```
dados/
â”œâ”€â”€ brutos/
â”‚   â”œâ”€â”€ treino_parte1.csv
â”‚   â”œâ”€â”€ treino_parte2.csv
â”‚   â””â”€â”€ itens/
â”‚       â”œâ”€â”€ itens-parte1.csv
â”‚       â””â”€â”€ itens-parte2.csv
```
### 4. Crie a imagem:
```bash
docker build -t sistema-recomendacao-g1 .
```

## ğŸš€ ExecuÃ§Ã£o Docker - pipeline nÃ£o executado

### 1. Execute o comando para criar o container:
```bash
docker run -p 5000:5000 -p 8000:8000 -e RUN_PIPELINE=true -v $(pwd)/dados:/app/dados -v $(pwd)/logs:/app/logs -v $(pwd)/modelos/modelos_salvos:/app/modelos/modelos_salvos --name recomendador sistema-recomendacao-g1 
```
### 2. Acesse a interface web da API:
```
http://localhost:8000
```

A documentaÃ§Ã£o Swagger estarÃ¡ disponÃ­vel localmente em:
```
http://localhost:8000/docs
```

## ğŸš€ ExecuÃ§Ã£o Docker - pipeline executado com dados processados e modelo treinado

##  **Paraesta etapa Ã© preciso apenas executar etapa 1 da InstalaÃ§Ã£o Docker**

### 1. Execute o comando para criar o container:
```bash
docker run -p 5000:5000 -p 8000:8000 -e RUN_PIPELINE=false --name recomendador cleberfx/sistema-recomendacao-g1:dados-processados-modelo-treinado 
```

### 2. Acesse a interface web da API:
```
http://localhost:8000
```

A documentaÃ§Ã£o Swagger estarÃ¡ disponÃ­vel localmente em:
```
http://localhost:8000/docs
```


## ğŸ—ï¸ Arquitetura

O sistema implementa uma arquitetura hÃ­brida de recomendaÃ§Ã£o que combina mÃºltiplas estratÃ©gias em diferentes fases:

### 1. Modelo Neural HÃ­brido

O componente principal utiliza duas estratÃ©gias de filtragem implementadas em um modelo neural profundo:

- **Filtragem Colaborativa**: Implementada atravÃ©s de embeddings de usuÃ¡rios e itens que capturam padrÃµes de interaÃ§Ã£o
- **Filtragem Baseada em ConteÃºdo**: Implementada atravÃ©s de vetores TF-IDF do texto das notÃ­cias

### 2. Fase de Scoring e RecomendaÃ§Ã£o

ApÃ³s a construÃ§Ã£o e treino do modelo neural, sÃ£o aplicadas estratÃ©gias adicionais:

#### 2.1 Para UsuÃ¡rios Existentes (Warm Start)
Utiliza todas as estratÃ©gias disponÃ­veis com a seguinte ponderaÃ§Ã£o:
- **60% Modelo Neural**: Combina filtragem colaborativa e baseada em conteÃºdo
- **25% Popularidade**: Score baseado no nÃºmero de interaÃ§Ãµes
- **15% RecÃªncia**: Peso temporal das notÃ­cias

#### 2.2 Para Novos UsuÃ¡rios (Cold Start)
Utiliza apenas estratÃ©gias independentes do histÃ³rico do usuÃ¡rio:
- **70% Popularidade**: NotÃ­cias mais acessadas
- **30% RecÃªncia**: PriorizaÃ§Ã£o de conteÃºdo atual

### 3. Pipeline de Processamento

```plaintext
Dados Brutos â†’ Preprocessamento Spark â†’ Features â†’ Modelo â†’ RecomendaÃ§Ãµes â†’ Serving
     â†“               â†“                     â†“          â†“          â†“             â†“
  CSV/JSON    Limpeza & TransformaÃ§Ã£o    TF-IDF    Neural   AplicaÃ§Ã£o de    API REST
                                                            EstratÃ©gias
```


### 4. Componentes do Sistema

#### 4.1 Preprocessamento (PySpark)
- Limpeza de dados
- NormalizaÃ§Ã£o de timestamps
- GeraÃ§Ã£o de features
- Processamento distribuÃ­do

#### 4.2 Modelo de RecomendaÃ§Ã£o
- Framework: TensorFlow 2.x
- Arquitetura Neural: Filtragem Colaborativa e AnÃ¡lise de ConteÃºdo
- Otimizador: Adam
- Loss: Binary Crossentropy


#### 4.3 EstratÃ©gias Adicionais de RecomendaÃ§Ã£o
- **Fatores Temporais**:
  - Pesos por perÃ­odo de tempo
  - PriorizaÃ§Ã£o de conteÃºdo recente
  - Decaimento temporal exponencial
- **Popularidade**:
  - Contagem de interaÃ§Ãµes por item
  - NormalizaÃ§Ã£o por perÃ­odos
  - Score dinÃ¢mico atualizado

#### 4.4 Servidor de APIs (Flask)
- REST API
- Swagger UI
- Cache

#### 4.5 MLflow
- Tracking de experimentos
- Registro de modelos
- Monitoramento de mÃ©tricas
- Versionamento

### 5. Monitoramento e MÃ©tricas

#### 5.1 MÃ©tricas do Modelo
- Accuracy
- Precision
- Recall
- Loss

#### 5.2 MÃ©tricas do Sistema
- LatÃªncia de resposta
- Taxa de acerto
- Diversidade das recomendaÃ§Ãµes
- Cobertura do catÃ¡logo

### 6. OtimizaÃ§Ãµes

- Batch predictions para eficiÃªncia
- Caching de recomendaÃ§Ãµes frequentes
- Processamento assÃ­ncrono
- Load balancing
- Checkpointing

### 7. SeguranÃ§a

- ValidaÃ§Ã£o de entrada
- SanitizaÃ§Ã£o de dados
- Logs de auditoria

### 8. Detalhamento da Arquitetura Neural

O sistema implementa uma arquitetura neural profunda que combina filtragem colaborativa e baseada em conteÃºdo, composta por 11 camadas principais organizadas em 6 grupos funcionais:

#### 8.1 Camadas de Entrada (3 camadas)
O modelo recebe trÃªs tipos de entrada:
- Entrada de UsuÃ¡rios: 1 neurÃ´nio (ID do usuÃ¡rio)
- Entrada de Itens: 1 neurÃ´nio (ID do item)
- Entrada de ConteÃºdo: 100 neurÃ´nios (vetor TF-IDF dos textos)

#### 8.2 Camadas de Embedding - Filtragem Colaborativa (2 camadas)
Implementa a filtragem colaborativa atravÃ©s de:
- Embedding de UsuÃ¡rios: 16 neurÃ´nios
- Embedding de Itens: 16 neurÃ´nios
CaracterÃ­sticas:
- Transforma IDs em vetores densos
- Captura padrÃµes latentes de interaÃ§Ã£o
- Aprende representaÃ§Ãµes automÃ¡ticas de preferÃªncias

#### 8.3 Camadas de Flatten (2 camadas)
Processamento dos embeddings:
- Flatten UsuÃ¡rios: 16 neurÃ´nios
- Flatten Itens: 16 neurÃ´nios

#### 8.4 Camada de ConcatenaÃ§Ã£o (1 camada)
FusÃ£o das diferentes abordagens:
- 132 neurÃ´nios totais (16 + 16 + 100)
- Unifica embeddings colaborativos
- Integra features de conteÃºdo
- Permite aprendizado conjunto dos padrÃµes

#### 8.5 Camadas Densas com RegularizaÃ§Ã£o (2 blocos)
Processamento profundo estruturado em:

Primeiro Bloco:
- Dense: 32 neurÃ´nios
- Layer Normalization: 32 neurÃ´nios
- Dropout: 30% dos neurÃ´nios

Segundo Bloco:
- Dense: 16 neurÃ´nios
- Layer Normalization: 16 neurÃ´nios
- Dropout: 30% dos neurÃ´nios

#### 8.6 Camada de SaÃ­da (1 camada)
- 1 neurÃ´nio com ativaÃ§Ã£o sigmoid
- Produz score entre 0 e 1
- Representa probabilidade de recomendaÃ§Ã£o

#### 8.7 Fluxo de Dados
1 â†’ 16 â†’ 16 â†’ 132 â†’ 32 â†’ 16 â†’ 1
(entrada â†’ embedding â†’ flatten â†’ concatenaÃ§Ã£o â†’ dense1 â†’ dense2 â†’ saÃ­da)

#### 8.8 EstratÃ©gias de RegularizaÃ§Ã£o
- RegularizaÃ§Ã£o L2: Controle de complexidade
- Dropout: ReduÃ§Ã£o de overfitting (30%)
- Layer Normalization: Estabilidade no treinamento
- Gradient Clipping: Previne explosÃ£o do gradiente

#### 8.9 Vantagens da Arquitetura
1. **Flexibilidade**
   - Combina mÃºltiplas fontes de informaÃ§Ã£o
   - AdaptÃ¡vel a diferentes tipos de conteÃºdo

2. **Performance**
   - Embeddings eficientes
   - RegularizaÃ§Ã£o robusta
   - Treinamento estÃ¡vel

3. **Escalabilidade**
   - Processamento em batch
   - Arquitetura modular
   - OtimizaÃ§Ã£o de memÃ³ria